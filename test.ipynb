{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Test:\n",
    "    def __init__(self, stuttering_folder: str = \"dataset/test/stutter\",\n",
    "                 no_stuttering_folder: str = \"dataset/test/noStutter\", classified: str = \"classification_model.h5\"):\n",
    "        self.stuttering_folder = stuttering_folder\n",
    "        self.no_stuttering_folder = no_stuttering_folder\n",
    "        self.classified = classified\n",
    "        self.test_model()\n",
    "\n",
    "    def test_model(self):\n",
    "        model = keras.models.load_model(self.classified)\n",
    "        audio_no_stutter = Files(self.no_stuttering_folder).files_audio()\n",
    "        print(audio_no_stutter)\n",
    "        audio_stutter = Files(self.stuttering_folder).files_audio()\n",
    "        test_vectors = []\n",
    "        test_labels = []\n",
    "        test_vectors_to = []\n",
    "        for i in range(len(audio_no_stutter)):\n",
    "            concatenated_vector_get = Method(audio_no_stutter[i]).get_concatenated_vector_get()\n",
    "            print(concatenated_vector_get)\n",
    "            prediction = model.predict(concatenated_vector_get)\n",
    "            binary_predictions = np.round(prediction).flatten()\n",
    "            print(\"binary_predictions[0] \", binary_predictions[0])\n",
    "            print(\"test_labels 0 \")\n",
    "\n",
    "            test_vectors_to.append(binary_predictions[0])\n",
    "            test_vectors.append(concatenated_vector_get)\n",
    "            test_labels.append(0)\n",
    "        for i in range(len(audio_stutter)):\n",
    "            concatenated_vector_get = Method(audio_stutter[i]).get_concatenated_vector_get()\n",
    "            test_vectors.append(concatenated_vector_get)\n",
    "            prediction = model.predict(concatenated_vector_get)\n",
    "            binary_predictions = np.round(prediction).flatten()\n",
    "            print(\"binary_predictions[0] \", binary_predictions[0])\n",
    "            print(\"test_labels 1 \")\n",
    "            test_vectors_to.append(binary_predictions[0])\n",
    "            test_labels.append(1)\n",
    "\n",
    "        precision = self.calculate_precision(test_labels, test_vectors_to)\n",
    "        recall = self.calculate_recall(test_labels, test_vectors_to)\n",
    "        f1_score = self.calculate_f1_score(test_labels, test_vectors_to)\n",
    "        accuracy = self.calculate_accuracy(test_labels, test_vectors_to)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"F1-score:\", f1_score)\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    def calculate_precision(self, labels, predicted_labels):\n",
    "        true_positives = 0\n",
    "        predicted_positives = 0\n",
    "        for i in range(len(predicted_labels)):\n",
    "            if predicted_labels[i] == 1:\n",
    "                predicted_positives += 1\n",
    "                if labels[i] == 1:\n",
    "                    true_positives += 1\n",
    "\n",
    "        precision = true_positives / predicted_positives if predicted_positives != 0 else 0\n",
    "        return precision\n",
    "\n",
    "    def calculate_recall(self,labels, predicted_labels):\n",
    "        true_positives = 0\n",
    "        actual_positives = 0\n",
    "        for i in range(len(predicted_labels)):\n",
    "            if labels[i] == 1:\n",
    "                actual_positives += 1\n",
    "                if predicted_labels[i] == 1:\n",
    "                    true_positives += 1\n",
    "        recall = true_positives / actual_positives if actual_positives != 0 else 0\n",
    "        return recall\n",
    "\n",
    "    def calculate_f1_score(self,labels, predicted_labels):\n",
    "        precision = self.calculate_precision(labels, predicted_labels)\n",
    "        recall = self.calculate_recall(labels, predicted_labels)\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "        return f1_score\n",
    "\n",
    "    def calculate_accuracy(self,labels, predicted_labels):\n",
    "        correct_predictions = 0\n",
    "        total_predictions = len(labels)\n",
    "        for i in range(len(predicted_labels)):\n",
    "            if labels[i] == predicted_labels[i]:\n",
    "                correct_predictions += 1\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "        return accuracy"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
